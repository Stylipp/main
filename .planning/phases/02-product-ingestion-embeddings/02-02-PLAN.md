---
phase: 02-product-ingestion-embeddings
plan: 02
type: execute
depends_on: ["02-01"]
files_modified: [apps/backend/src/features/ai/service/embedding_service.py, apps/backend/src/features/ai/router/router.py, apps/backend/src/features/ai/schemas/schemas.py, apps/backend/pyproject.toml, apps/backend/src/main.py]
domain: backend
---

<objective>
Implement FashionSigLIP embedding service for generating 768-dimensional fashion image embeddings.

Purpose: Enable semantic similarity search by converting product images into vector representations.
Output: EmbeddingService class loaded at startup with semaphore-limited inference, health check endpoint.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-plan.md
./summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/02-product-ingestion-embeddings/02-01-SUMMARY.md
@apps/backend/src/main.py
@apps/backend/src/core/config.py
@apps/backend/src/features/storage/service/service.py

**Tech stack available:** FastAPI, transformers, torch, asyncio
**Established patterns:** Feature folder convention (features/ai/{service,router,schemas}/), lifespan for startup
**Model details:**
- Marqo/marqo-fashionSigLIP from Hugging Face
- 768-dimensional output, normalized for cosine similarity
- Apache 2.0 license
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add ML dependencies and create embedding service</name>
  <files>apps/backend/pyproject.toml, apps/backend/src/features/ai/__init__.py, apps/backend/src/features/ai/service/__init__.py, apps/backend/src/features/ai/service/embedding_service.py</files>
  <action>
Add dependencies to pyproject.toml:
- transformers>=4.40.0
- torch>=2.0.0 (CPU only, no CUDA suffix)
- Pillow>=10.0.0

Create features/ai/ directory structure following convention.

Create EmbeddingService class in embedding_service.py:
```python
class EmbeddingService:
    def __init__(self, max_concurrent: int = 4):
        self.model = None
        self.processor = None
        self._semaphore = asyncio.Semaphore(max_concurrent)
        self._loaded = False

    def load_model(self) -> None:
        """Load model at startup. Call once."""
        from transformers import AutoModel, AutoProcessor
        self.model = AutoModel.from_pretrained(
            'Marqo/marqo-fashionSigLIP',
            trust_remote_code=True
        )
        self.processor = AutoProcessor.from_pretrained(
            'Marqo/marqo-fashionSigLIP',
            trust_remote_code=True
        )
        self.model.eval()
        self._loaded = True

    async def get_embedding(self, image: Image.Image) -> list[float]:
        """Generate 768-dim embedding from PIL Image."""
        if not self._loaded:
            raise RuntimeError("Model not loaded. Call load_model() first.")
        async with self._semaphore:
            return await asyncio.to_thread(self._inference, image)

    async def get_embeddings_batch(self, images: list[Image.Image]) -> list[list[float]]:
        """Generate embeddings for multiple images."""
        # Process in batches of 8 for memory efficiency
        ...

    def _inference(self, image: Image.Image) -> list[float]:
        import torch
        with torch.no_grad():
            inputs = self.processor(images=[image], return_tensors="pt")
            features = self.model.get_image_features(
                inputs['pixel_values'],
                normalize=True
            )
            return features[0].tolist()

    @property
    def is_loaded(self) -> bool:
        return self._loaded
```

Include proper type hints and docstrings.
  </action>
  <verify>cd apps/backend && python -c "from src.features.ai.service.embedding_service import EmbeddingService; print('Import OK')"</verify>
  <done>EmbeddingService class created with load_model, get_embedding, get_embeddings_batch methods</done>
</task>

<task type="auto">
  <name>Task 2: Create embedding service schemas</name>
  <files>apps/backend/src/features/ai/schemas/__init__.py, apps/backend/src/features/ai/schemas/schemas.py</files>
  <action>
Create Pydantic schemas for AI feature:

```python
from pydantic import BaseModel, Field

class EmbeddingRequest(BaseModel):
    image_url: str = Field(..., description="URL of image to embed")

class EmbeddingResponse(BaseModel):
    embedding: list[float] = Field(..., description="768-dimensional embedding vector")
    dimension: int = Field(default=768)

class EmbeddingHealthResponse(BaseModel):
    status: str
    model_loaded: bool
    model_name: str = "Marqo/marqo-fashionSigLIP"
    embedding_dimension: int = 768
```

Export from __init__.py.
  </action>
  <verify>cd apps/backend && python -c "from src.features.ai.schemas import EmbeddingRequest, EmbeddingResponse, EmbeddingHealthResponse; print('Schemas OK')"</verify>
  <done>Pydantic schemas created for embedding request/response and health check</done>
</task>

<task type="auto">
  <name>Task 3: Create router and integrate with FastAPI lifespan</name>
  <files>apps/backend/src/features/ai/router/__init__.py, apps/backend/src/features/ai/router/router.py, apps/backend/src/main.py</files>
  <action>
Create router in features/ai/router/router.py:
- GET /api/ai/health - Returns model status (loaded, dimension, name)
- POST /api/ai/embed - Accept image URL, return embedding (for testing only)

Router should get EmbeddingService from app.state.embedding_service.

Update main.py lifespan to:
1. Create EmbeddingService instance
2. Call load_model() at startup (this will download model on first run)
3. Store in app.state.embedding_service
4. Include AI router

Add logging for model load time (import time module).

Note: The /api/ai/embed endpoint is for testing. In production, embeddings are generated during ingestion, not on-demand.
  </action>
  <verify>cd apps/backend && python -c "from src.main import app; print('App imports OK')"</verify>
  <done>AI router created with health endpoint, EmbeddingService loaded at startup via lifespan</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `pip install -e .` installs all new dependencies
- [ ] EmbeddingService loads model successfully (first run downloads ~600MB)
- [ ] GET /api/ai/health returns model_loaded: true
- [ ] No import errors in main.py
</verification>

<success_criteria>

- FashionSigLIP model loads at startup
- EmbeddingService provides async get_embedding method
- Semaphore limits concurrent inference to 4
- Health endpoint confirms model status
- All 02-01 functionality still works
</success_criteria>

<output>
After completion, create `.planning/phases/02-product-ingestion-embeddings/02-02-SUMMARY.md`
</output>
